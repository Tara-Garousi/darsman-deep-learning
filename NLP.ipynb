{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3KEE4G8MZSzIa+Wwqm958",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdiabbasidev/darsman-deep-learning/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MDzPCGnjDOki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras"
      ],
      "metadata": {
        "id": "Awh1Iyg3vxim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "mkHOeW-ygmGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# texts = [\n",
        "#     \"I love machine learning and deep learning\",\n",
        "#     \"The weather is great today\",\n",
        "#     \"This is a terrible movie!\",\n",
        "#     \"I am learning natural language processing\",\n",
        "#     \"The movie was fantastic and amazing\",\n",
        "#     \"I hate bad weather\",\n",
        "#     \"Deep learning is a subset of machine learning\",\n",
        "#     \"I really love the new design!\",\n",
        "#     \"This is so disappointing\",\n",
        "#     \"The food was delicious\",\n",
        "#     \"I absolutely love this phone, it's fantastic!\",\n",
        "#     \"The service at this restaurant was terrible\",\n",
        "#     \"I am so happy with my new shoes\",\n",
        "#     \"The movie was a complete waste of time\",\n",
        "#     \"This hotel has the best view in the city\",\n",
        "#     \"I am very disappointed with this product\",\n",
        "#     \"The food was cold and tasteless\",\n",
        "#     \"The new update is amazing and works perfectly\",\n",
        "#     \"I regret buying this laptop, it’s so slow\",\n",
        "#     \"The concert was truly unforgettable!\",\n",
        "#     \"The packaging was damaged when it arrived\",\n",
        "#     \"I had a great time at the party\",\n",
        "#     \"The customer service was rude and unhelpful\",\n",
        "#     \"This is the best coffee I've ever had!\",\n",
        "#     \"The app keeps crashing and it's really annoying\",\n",
        "#     \"I can't believe how fast the delivery was!\",\n",
        "#     \"The product didn’t match the description\",\n",
        "#     \"I enjoyed every minute of the performance\",\n",
        "#     \"The quality of the material is poor\",\n",
        "#     \"I am thrilled with the results of the treatment\",\n",
        "#     \"The car broke down just after a week of buying it\",\n",
        "#     \"I can’t wait to visit this place again\",\n",
        "#     \"The product arrived late and it’s defective\",\n",
        "#     \"The staff was incredibly helpful and polite\",\n",
        "#     \"I wouldn't recommend this service to anyone\",\n",
        "#     \"The course was very informative and well taught\",\n",
        "#     \"This chair is so uncomfortable, I want a refund\",\n",
        "#     \"The vacation was a dream come true\",\n",
        "#     \"The software is buggy and difficult to use\",\n",
        "# ]\n",
        "\n",
        "texts = [\n",
        "    \"من عاشق یادگیری ماشین و یادگیری عمیق هستم.\",\n",
        "    \"امروز هوا فوق‌العاده است.\",\n",
        "    \"این فیلم وحشتناک بود!\",\n",
        "    \"من در حال یادگیری پردازش زبان طبیعی هستم.\",\n",
        "    \"این فیلم شگفت‌انگیز و فوق‌العاده بود.\",\n",
        "    \"من از آب‌وهوای بد متنفرم.\",\n",
        "    \"یادگیری عمیق زیرمجموعه‌ای از یادگیری ماشین است.\",\n",
        "    \"من واقعاً از طراحی جدید خیلی خوشم می‌آید!\",\n",
        "    \"این واقعاً ناامیدکننده است.\",\n",
        "    \"غذا بسیار خوشمزه بود.\",\n",
        "    \"من کاملاً عاشق این گوشی هستم، خیلی فوق‌العاده است!\",\n",
        "    \"خدمات این رستوران افتضاح بود.\",\n",
        "    \"من از کفش‌های جدیدم خیلی خوشحالم.\",\n",
        "    \"این فیلم کاملاً اتلاف وقت بود.\",\n",
        "    \"این هتل بهترین منظره را در شهر دارد.\",\n",
        "    \"من واقعاً از این محصول ناراضی هستم.\",\n",
        "    \"غذا سرد و بی‌مزه بود.\",\n",
        "    \"به‌روزرسانی جدید شگفت‌انگیز است و به‌خوبی کار می‌کند.\",\n",
        "    \"پشیمانم که این لپ‌تاپ را خریدم، خیلی کند است.\",\n",
        "    \"این کنسرت واقعاً فراموش‌نشدنی بود!\",\n",
        "    \"بسته‌بندی هنگام تحویل آسیب دیده بود.\",\n",
        "    \"در مهمانی خیلی خوش گذشت.\",\n",
        "    \"خدمات مشتری بی‌ادب و بی‌فایده بود.\",\n",
        "    \"این بهترین قهوه‌ای است که تا حالا خورده‌ام!\",\n",
        "    \"برنامه مدام خراب می‌شود و واقعاً اعصاب‌خردکن است.\",\n",
        "    \"نمی‌توانم باور کنم که تحویل چقدر سریع بود!\",\n",
        "    \"محصول با توضیحات مطابقت نداشت.\",\n",
        "    \"از هر لحظه اجرای نمایش لذت بردم.\",\n",
        "    \"کیفیت مواد ضعیف است.\",\n",
        "    \"از نتایج درمان بسیار خوشحال هستم.\",\n",
        "    \"ماشین درست یک هفته بعد از خرید خراب شد.\",\n",
        "    \"منتظر نیستم دوباره از این مکان بازدید کنم.\",\n",
        "    \"محصول دیر رسید و معیوب بود.\",\n",
        "    \"پرسنل فوق‌العاده کمک‌رسان و مودب بودند.\",\n",
        "    \"این خدمات را به هیچ‌کس توصیه نمی‌کنم.\",\n",
        "    \"این دوره بسیار آموزنده و خوب تدریس شده بود.\",\n",
        "    \"این صندلی بسیار ناراحت‌کننده است، من پولم را می‌خواهم.\",\n",
        "    \"این تعطیلات مثل یک رؤیا بود.\",\n",
        "    \"نرم‌افزار پر از باگ است و استفاده از آن سخت است.\",\n",
        "    \"در اسپا تجربه‌ای فوق‌العاده داشتم.\"\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,1\n",
        "]\n",
        "print(f\"Texts Size : {len(texts)}\")\n",
        "print(f\"Labels Size : {len(labels)}\")"
      ],
      "metadata": {
        "id": "bD7tXBZqfAVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer =keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "for text, seq in zip(texts, sequences):\n",
        "    print(f\"{text.ljust(60)}{(str(seq)).ljust(20)}\")"
      ],
      "metadata": {
        "id": "ruy-x56sfD9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 12\n",
        "X_train = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length)\n",
        "y_train = np.array(labels, dtype='float32')\n",
        "\n",
        "\n",
        "for text_item, x_train_item in zip(texts, X_train):\n",
        "    print(f\"{text_item.ljust(60)}{(str(x_train_item)).ljust(20)}\")"
      ],
      "metadata": {
        "id": "afVM7_z3fKUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = keras.layers.Input(shape=(max_length,))\n",
        "\n",
        "embedding_layer = keras.layers.Embedding(input_dim=10000, output_dim=64, input_length=max_length)\n",
        "\n",
        "embedding_output = embedding_layer(input_layer)\n",
        "\n",
        "flatten_layer = keras.layers.Flatten()(embedding_output)\n",
        "\n",
        "dense_layer1 = keras.layers.Dense(64, activation='relu')(flatten_layer)\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid')(dense_layer1)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6td9eEEsBEvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=4, validation_split=0.2,verbose=0)"
      ],
      "metadata": {
        "id": "XWfW_PXmgCKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1fS14hcvkt4"
      },
      "outputs": [],
      "source": [
        "# test_texts = [\n",
        "#     \"The new design is truly amazing and fantastic\",\n",
        "#     \"The service was rude and disappointing\",\n",
        "#     \"The app is crashing constantly, and it’s really annoying\",\n",
        "#     \"The weather is awful today\",\n",
        "#     \"I am very happy with my purchase of this new laptop\",\n",
        "# ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_texts = [\n",
        "    \"طراحی جدید واقعاً شگفت‌انگیز و فوق‌العاده است.\",\n",
        "    \"خدمات افتضاح و ناامیدکننده بود.\",\n",
        "    \"از خرید این لپ‌تاپ جدید خیلی خوشحالم.\",\n",
        "    \"برنامه مدام خراب می‌شود و خیلی اعصاب‌خردکن است.\",\n",
        "    \"امروز هوا افتضاح است.\",\n",
        "]\n",
        "\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "X_test = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=max_length)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predicted_classes = (predictions >= 0.5).astype(int)\n",
        "\n",
        "for text, prob, cls in zip(test_texts, predictions, predicted_classes):\n",
        "    print(f\"{text.ljust(60)}{(str(cls[0])).ljust(20)}{f'{prob[0]:.4f}'.ljust(20)}\")"
      ]
    }
  ]
}