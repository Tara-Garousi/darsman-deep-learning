{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jA77cRvttQwP3BVpfTxAMSQOrecQp643",
      "authorship_tag": "ABX9TyNloqIIGgLc7AIwzkz3Z7Na",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdiabbasidev/darsman-deep-learning/blob/main/Conv2dFilterAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "jlhOafDUkxHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EX1"
      ],
      "metadata": {
        "id": "tsb11OpeVq0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input data\n",
        "sample_number=4\n",
        "image_width=28\n",
        "image_height=28\n",
        "channel_number=3\n",
        "input_shape = (sample_number, image_width, image_height, channel_number)\n",
        "input_data = tf.random.normal(input_shape)\n",
        "print(input_data.shape)"
      ],
      "metadata": {
        "id": "AI-iEmc3UCc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(sample_number, channel_number, figsize=(10, 10))\n",
        "for i in range(sample_number):\n",
        "    for channel_index in range(channel_number):\n",
        "        data = np.zeros_like(input_data[0].numpy())\n",
        "        data[:, :, channel_index] = input_data[i, :, :, channel_index]\n",
        "        data = np.clip(data, 0, 1)\n",
        "        ax = axes[i, channel_index]\n",
        "        ax.imshow(data)\n",
        "        ax.set_title(f\"Image {i + 1} - {['Red', 'Green', 'Blue'][channel_index]}\")\n",
        "        ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7LS45hhVpyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2D convolutional layer with specified filters\n",
        "filters=5\n",
        "kernel_size=3\n",
        "strides=1\n",
        "conv2d = keras.layers.Conv2D(\n",
        "                              filters=filters,\n",
        "                              kernel_size=kernel_size,\n",
        "                              strides=strides,\n",
        "                              padding=\"same\",                # padding=\"valid\"  or padding=\"same\"\n",
        "                              activation='relu')\n",
        "conv_output = conv2d(input_data)\n",
        "print(conv_output.shape)"
      ],
      "metadata": {
        "id": "0sOMoEqHVAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract filter weights from the convolutional layer\n",
        "filter_weights, _ = conv2d.get_weights()\n",
        "\n",
        "for i in range(filters):\n",
        "    print(f\"Filter {i+1} weights:\")\n",
        "    print(filter_weights[:, :, :, i])\n",
        "    print(100 * \"*\")"
      ],
      "metadata": {
        "id": "cSxDQDTmVMwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the output of each filter for the first input sample\n",
        "for i in range(filters):\n",
        "    output = conv_output[0, :, :, i]\n",
        "    print(output.numpy())\n",
        "    print(100 * \"*\")"
      ],
      "metadata": {
        "id": "usd8YlgJVdlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of output the first sample\n",
        "for i in range(filters):\n",
        "  output=conv_output[0, :, :, i]\n",
        "  plt.imshow(output.numpy(), cmap='gray')\n",
        "  plt.title(f\"Output {i+1} \")\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "gAJgOoTGVgOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EX2"
      ],
      "metadata": {
        "id": "blq6oTmWVNqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all image files in the folder\n",
        "image_folder = \"/content/drive/MyDrive/images/images280x280\"\n",
        "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "num_images = len(image_files)                       # Number of images\n",
        "channel_number=3                                    # Number of iamge channels"
      ],
      "metadata": {
        "id": "4kgk_1ZhidSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open and process images\n",
        "images = []\n",
        "for image_file in image_files[:num_images]:\n",
        "    img = Image.open(image_file)\n",
        "    img = img.resize((280, 280))\n",
        "    img = img.convert('RGB')\n",
        "    images.append(np.array(img))"
      ],
      "metadata": {
        "id": "LamZwBrdi0Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a list of images to a NumPy array\n",
        "dataset = np.array(images, dtype=np.float32) / 255.0              # Normalize values ​​to the interval [0, 1]\n",
        "\n",
        "# Convert to TensorFlow\n",
        "input_data = tf.convert_to_tensor(dataset)\n",
        "print(input_data.shape)"
      ],
      "metadata": {
        "id": "S65pz35HjGQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters=8\n",
        "kernel_size=3\n",
        "strides=1\n",
        "conv2d = keras.layers.Conv2D(\n",
        "                              filters=filters,\n",
        "                              kernel_size=kernel_size,\n",
        "                              strides=strides,\n",
        "                              padding=\"same\",             # padding=\"valid\"  or padding=\"same\"\n",
        "                              activation='relu')\n",
        "conv_output = conv2d(input_data)\n",
        "\n",
        "print(conv_output.shape)"
      ],
      "metadata": {
        "id": "W1jitmAkheWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Tensor to numpy Array\n",
        "conv_output_np = conv_output.numpy()\n",
        "\n",
        "fig, axes = plt.subplots(num_images, filters, figsize=(10, 10))\n",
        "for i in range(num_images):\n",
        "    for filter_index in range(filters):\n",
        "        ax = axes[i, filter_index]\n",
        "        ax.imshow(conv_output_np[i, :, :, filter_index], cmap='gray')\n",
        "        ax.set_title(f\"I{i + 1} - Filter {filter_index + 1}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dGTWDm7eorQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract filter weights from the convolutional layer\n",
        "filter_weights, _ = conv2d.get_weights()\n",
        "\n",
        "for i in range(filters):\n",
        "    print(f\"Filter {i+1} weights:\")\n",
        "    print(filter_weights[:, :, :, i])\n",
        "    print(100 * \"*\")"
      ],
      "metadata": {
        "id": "5r1kHHFNJV-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Tensor to numpy Array\n",
        "fig, axes = plt.subplots(filters, channel_number, figsize=(10, 10))\n",
        "\n",
        "for filter_index in range(filters):\n",
        "    for channel_index in range(channel_number):\n",
        "        ax = axes[filter_index, channel_index]\n",
        "        ax.imshow(filter_weights[:, :, channel_index, filter_index], cmap='gray')\n",
        "        ax.set_title(f\"Filter {filter_index + 1} - Channel {channel_index + 1}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vv9y7JCCM3Fg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}